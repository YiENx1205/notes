# 前言

DB：DataBase数据库

DBMS：DataBase Management System数据库管理系统

DQL：Data Query Language查询语句

- select查询

DML：Data Manipulation Language数据操作语言

- 增insert、删delete、改update
- 针对表中数据

DDL：Data Definition Language数据定义语言

- 针对表结构
- create新建、drop删除、alter修改

TCL：Transaction Control Language事务控制语言

DCL：Data Control Language数据控制语言

- 授权grant、撤销权限revoke

<br>

# 存储引擎

存储引擎就是表处理器

## InnoDB

MySQL8.0之后的默认存储引擎，5.5之前是MyIASM。

**特点**

- 支持`事务`
- 支持数据库崩溃后自动恢复机制，安全
- 支持`外键约束`（仅有它支持），并支持`行级锁`，因此支持写并发
- 不存储总行
- 主键索引采用聚簇索引（并且索引的数据域存储数据文件本身），辅助索引（二级索引、非聚簇索引）的数据域存储主键值；因此从辅助索引查找数据，需要先通过辅助索引找到主键值，再回表访问聚簇索引。

<br>

## MyIASM

**特点**

- 可以转换为压缩、只读表来节省空间
- 不支持事务，安全性低
- 支持`表级锁`，每次操作都是对整个表加锁
- 储存表的总行数
- 采用`非聚集索引`，索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本一致，但是辅索引不用保证唯一性

<br>

**MyISAM和InnoDB区别**

- 都是B+tree索引

| InnoDB                 | MyISAM                         |
| ---------------------- | ------------------------------ |
| 聚簇索引               | 非聚簇索引                     |
| 数据和索引一起保存.ibd | 表结构.frm、索引.myi、数据.myd |
| 支持事务、外键、行表锁 | 不支持事务，支持表锁           |
| 更新快                 | 查询快                         |

- MyISAM适合读多更新少的：索引和数据分开储存，因此读取更快
- InnoDB适合插入更新频繁：索引和数据一起放。建立索引复杂，使用行锁，更新频繁效率更高

<br>

## MEMORY

- 数据存储在内存中

- 行的长度固定

- 速度快

**优点**：查询效率最高，不需要和硬盘交互

**缺点**：不安全，关机后数据消失，因为数据和索引都是在内存当中



<br>

# 事务

一个事务其实就是一个完整的业务逻辑，是一个最小的工作单元。不可再分。

**事务：就是批量的DML语句同时成功，或者同时失败！**

- 提交事务？commit
	- 清空事务性活动的日志文件，**将数据全部彻底持久化到数据库表中**。
	- 提交事务标志着，事务的结束。并且是一种**全部成功**的结束。

- 回滚事务？rollback
	- 将之前所有的**DML操作全部撤销**，并且清空事务性活动的日志文件。
	- 回滚事务标志着，事务的结束。并且是一种**全部失败**的结束。
	- 回滚只能回滚至上一次提交点。

<br>

## 一、事务的四个特性（ACID）

- A：原子性
	- 不可分割的最小单元
- C：一致性
	- 操作前后，总量不变
	- 在同一个事务当中，所有操作必须同时成功，或者同时失败
- I：隔离性
	- 多事务操作间不会相互影响
- D：持久性
	- 提交后，表中数据发生真的变化



<br>

## 二、事务的隔离级别

1. **读未提交** - read uncommitted （最低级）
	- 没有提交就读到了
	- 事务A可以读取到事务B未提交的数据。
2. **读已提交** - read committed
	- 提交之后才能读到
	- 事务A只能读取到事务B提交之后的数据。
	- oracle数据库默认的隔离级别是：read committed
	- 解决了脏读现象
3. **可重复读** - repeatable read
	- 提交之后也读不到，永远读取的都是刚开启事务时的数据
	- 事务A开启之后，不管是多久，每一次在事务A中读取到的数据都是一致的。即使事务B将数据已经修改，并且提交了，事务A读取到的数据还是没有发生改变，这就是可重复读。
	- 解决了不可重复读的问题
	- MySQL默认
4. 序列化/串行化 - serializable （最高级）
	- 事务排队，不能并发

<br>

### 脏读、不可重复读、幻读

1. 脏读
	- 一个未提交事务读取到另一个未提交事务的数据
2. 不可重复读
	- 一个未提交事务读取到了另一个提交事务**修改**的数据
	- 同样的条件，你读取过的数据，再次读取出来发现值不一样了。
3. 幻读
	- 一个未提交事务读取到另一个提交事务的**添加**（增删）数据
	- 系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入（注意是插入或者删除，不是修改）了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样。这就叫幻读。
	- 对InnoDB不可能

**通过设置隔离级别，解决读问题**

|          | 脏读 | 不可重复读 | 幻读 |
| -------- | ---- | ---------- | ---- |
| 读未提交 | 有   | 有         | 有   |
| 读已提交 | 无   | 有         | 有   |
| 可重复读 | 无   | 无         | 有   |
| 串行化   | 无   | 无         | 无   |

> 基本不用读未提交和串行化
>
> MySQL 在可重复读隔离级别上也一同解决了幻读：因为使用了 MVCC

### 如何解决脏读、幻读、不可重复读？

1. 读操作利用 MVCC，写操作进行加锁
	- 读-写 操作彼此并不冲突， 性能更高。 
2. 读写都用加锁操作
	- 读-写 操作彼此需要排队执行 ，影响性能。



## 三、事务日志

- 事务的隔离性由 `锁机制` 实现。
- 而事务的原子性、一致性和持久性由事务的 redo 日志和undo 日志来保证。
	- REDO LOG 称为 `重做日志` ，提供再写入操作，恢复提交事务修改的页操作，用来保证事务的`持久性`。
		- 记录的是数据页的`物理变化`，具体的数据，如页号、偏移量等
	- UNDO LOG 称为 `回滚日志` ，回滚行记录到某个特定版本，用来保证事务的`原子性`、`一致性`。
		- 记录的是`逻辑操作`，如进行 INSERT 后，记录一条相反的 DELETE 操作。
	- undo 不是 redo 的逆过程



<br>

# 数据库的设计规范

- 第一范式：要求任何一张表必须有主键，每一个字段**原子性不可再分**。

- 第二范式：建立在第一范式的基础之上，要求所有非主键字段完全依赖主键，**不要产生部分依赖**。

- 第三范式：建立在第二范式的基础之上，要求所有非主键字段直接依赖主键，**不要产生传递依赖**。

<br>

## 一、第一范式

必须有主键，并且每一个字段都是原子性不可再分。

```
学生编号    学生姓名      联系方式
------------------------------------------
1001        张三        zs@gmail.com,1359999999
1002        李四        ls@gmail.com,13699999999
1001        王五        ww@163.net,13488888888
```

不满足第一范式，第一：没有主键。第二：联系方式可以分为邮箱地址和电话

```
学生编号(pk)    学生姓名         邮箱地址         联系电话
----------------------------------------------------------
1001            张三        zs@gmail.com    1359999999
1002            李四        ls@gmail.com    13699999999
1003            王五        ww@163.net      13488888888
```

<br>

## 二、第二范式

建立在第一范式的基础之上，要求所有非主键字段必须完全依赖主键，不要产生部分依赖。

```
学生编号 学生姓名 教师编号 教师姓名
-------------------------------
1001     张三     001    王老师
1002     李四     002    赵老师
1003     王五     001    王老师
1001     张三     002    赵老师
```

这张表描述了学生和老师的关系：（1个学生可能有多个老师，1个老师有多个学生）

这是非常典型的：**多对多关系！**

无主键，不满足第一范式，修改

```
学生编号+教师编号(pk)   学生姓名   教师姓名
---------------------------------------
1001      001         张三      王老师
1002      002         李四      赵老师
1003      001         王五      王老师
1001      002         张三      赵老师
```

学生编号 教师编号，两个字段联合做主键，复合主键（PK: 学生编号+教师编号）

经过修改之后，以上的表满足了第一范式。但是满足第二范式吗？

不满足，“张三”依赖1001，“王老师”依赖001，显然产生了部分依赖。

**产生部分依赖有什么缺点？**

- 数据冗余了，空间浪费了。“张三”重复了，“王老师”重复了。

<br>

使用三张表来表示多对多的关系！！！！

多对多设计：**多对多，三张表，关系表两个外键**

```
学生表
学生编号(pk)    学生名字
-----------------------
1001            张三
1002            李四
1003            王五

教师表
教师编号(pk)    教师姓名
-----------------------
001            王老师
002            赵老师

学生教师关系表
id(pk)      学生编号(fk)     教师编号(fk)
----------------------------------------
1             1001             001
2             1002             002
3             1003             001
4             1001             002
```

<br>

## 三、第三范式

第三范式建立在第二范式的基础之上

要求所有非主键字典必须直接依赖主键，不要产生传递依赖。

```
学生编号（PK） 学生姓名 班级编号  班级名称
--------------------------------------
1001          张三     01     一年一班
1002          李四     02     一年二班
1003          王五     03     一年三班
1004          赵六     03     一年三班
```

> 一对多，一个教室有多个学生
>
> - 是否满足第一范式？满足，有主键
>
> - 是否满足第二范式？满足，主键不是复合主键，没有产生部分依赖
>
> - 是否满足第三范式？
>
> 	- 第三范式要求：不要产生传递依赖！
>
> 		一年一班依赖01，01依赖1001，产生了传递依赖。
>
> 		不符合第三范式的要求。产生了数据的冗余。



一对多设计：**一对多，两张表，多的表加外键**

```
班级表：一
班级编号(pk)     班级名称
-------------------------
01              一年一班
02              一年二班
03              一年三班


学生表：多
学生编号（PK）  学生姓名    班级编号(fk)
-------------------------------------
1001           张三         01            
1002           李四         02            
1003           王五         03            
1004           赵六         03 
```

<br>

**口诀**

- 一对一，外键唯一
- 多对多，三张表，关系表两个外键
- 一对多，两张表，多的表加外键

<br>

## 四、巴斯-科德范式

在第三范式的改进

若一个关系达到了第三范式，并且只有一个候选键，或者每个候选键都是单属性，则该关系自然达到 BC 范式

## 五、第四范式



## 六、第五范式



# 约束

非空约束：not null

唯一性约束: unique

主键约束: primary key （简称PK）

外键约束：foreign key（简称FK） 

检查约束：check（mysql不支持，oracle支持）

## 为什么自增主键不连续？

- **事务回滚**（自增值不能回退，因为并发插入数据时，回退自增ID可能造成主键冲突）
- **唯一键冲突**（由于表的自增值已变，但是主键发生冲突没插进去，下一次插入主键=现在变了的自增值+1，所以不连续）

eg：

假设，表t里面已经有了(1,1,1)这条记录，这时我再执行一条插入数据命令：

```mysql
insert into t values(null, 1, 1); (自增id,唯一键c,普通字段d)
```

执行流程：

1. 执行器调用InnoDB引擎接口写入一行，传入的这一行的值是(0,1,1);
2. InnoDB发现用户没有指定自增id的值，获取表t当前的自增值2；
3. 将传入的行的值改成(2,1,1)；
4. 将表的自增值改成3；
5. 继续执行插入数据操作，由于已经存在c=1的记录，所以报Duplicate key error，语句返回。

这个表的自增值改成3，是在真正执行插入数据的操作之前。这个语句真正执行的时候，因为碰到唯一键c冲突，所以id=2这一行并没有插入成功，但也没有将自增值再改回去。

所以，在这之后，再插入新的数据行时，拿到的自增id就是3。也就是说，出现了自增主键不连续的情况。



## 主键设计

### 雪花算法

##### 背景

需要选择合适的方案去应对数据规模的增长，以应对逐渐增长的访问压力和数据量。

数据库的扩展方式主要包括:业务分库、主从复制，数据库分表。

##### 数据库分表

垂直分表

水平分表

**核心思想**

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205062237939.png" alt="image-20220506223726597" style="zoom:50%;" />

一共64位，long 型

首先是一个符号位，1bit标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负 数是1，所以id一般是正数，最高位是0。

41bit时间截(毫秒级)，存储的是时间截的差值(当前时间截 - 开始时间截)，结果约等于69.73年。 

10bit作为机器的ID(5个bit是数据中心，5个bit的机器ID，可以部署在1024个节点)。 

12bit作为毫秒内的流水号(意味着每个节点在每毫秒可以产生 4096 个 ID)。

### UUID

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205062238676.png" alt="image-20220506223832810" style="zoom:50%;" />

UUID = 时间+UUID版本(16字节)- 时钟序列(4字节) - MAC地址(12字节)

其中还有四位多余的 -

所以一共36字节

**为什么UUID是随机无序的呢?**

因为UUID的设计中，将时间低位放在最前面，而这部分的数据是一直在变化的，并且是无序。



<br>

# 索引

**索引的本质:** `索引是数据结构`。排好序的数据结构，可以帮助快速查找数据，缩小扫描范围。

> 对于表来讲，**只要是主键或者加有unique约束的字段上会自动创建索引**

<br>

**优点**

1. 提高检索效率，降低`数据库的IO传输成本`
	- 降低IO成本是创建索引的主要目标，下面都是附带的
	- 索引是存储在外部磁盘中的
2. 通过创建唯一索引，保证表中`每行数据的唯一性`
3. `加速表和表之间的连接`，对于有依赖关系的子表和父表联合查询时，可以提高查询速度
4. 在group分组和order排序进行数据查询时，可以`减少查询中分组和排序的时间`

<br>

**考虑添加索引的条件**

- 条件1：数据量庞大（到底有多么庞大算庞大，这个需要测试，因为每一个硬件环境不同）

- 条件2：该字段经常出现在where的后面，以条件的形式存在，也就是说这个字段总是被扫描。

- 条件3：该字段很少的DML(insert delete update)操作。（因为DML之后，索引需要重新排序。）

详细见设计原则

<br>

**建议不要随意添加索引**，

- 因为索引也是需要动态维护的，太多的话反而会降低系统的性能，降低更新表的速度
- 而且索引会占据一定的物理空间，存储在磁盘上。

> **百万级数据量的删除（插入）**：索引可以提高查询的速度，但是会影响插入记录的速度。这种情况下，最好的办法是**先删除**表中的索引，然**后删除（插入）**数据，插入完成后**再创建索引**。

<br>

## 一、常见的索引概念

按照物理实现形式，氛围**聚簇索引**和**非聚簇索引**（又称辅助索引、二级索引）

> 聚簇：表示数据行和相邻的键值聚簇的存储在一起

<br>

数据库管理存储空间的基本单位是`页`，数据库IO操作的最小单位是`页`，一页`16kb`

<br>

记录的格式

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202203271340960.png" width=300px />

每页的格式

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202203271340027.png" alt="image-20220327134057424" width=400px />

以下以InnoDB为例

### 1、聚簇索引

橙色：key

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202203271345391.png" alt="image-20220327131631604" />

<br>

特点：

- `叶子结点`存储的是完整的用户记录
- `页内`的记录是个`单向链表`
- 存放`用户记录的页`以及存放`目录项记录的页`，页和页之间组成双向链表

聚簇索引会被InnoDB默认创建，默认`自增主键`

优点：

- `数据访问快`，索引和数据在一个B+树中
- 对于主键的`排序查找`和`范围查找`速度快

缺点：

- 插入速度严重依赖于插入顺序，因为是排序的，所以会导致重新排序
- 更新主键的代价高

<br>

### 2、非聚簇索引

以c2为索引，即以c2列的大小作为排序规则：

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202203271358007.png" alt="image-20220327135830613" style="zoom:67%;" />

> 真实中二级索引的目录项中也会保存主键值，避免目录项值相同的情况

**回表**：通过索引找到主键，再根据主键id去主键索引查。

- 一个聚簇，多个非聚簇

**索引下推**：

- 在根据索引查询过程中就根据查询条件过滤掉一些记录，减少最后的回表操作

<br>

**非聚簇索引一定会回表吗**

- 覆盖索引：索引字段覆盖了查询语句涉及的字段，直接通过索引文件就可以返回查询所需的数据，不必通过回表操作
- **总结**：覆盖索引就不走回表

<br>

### 3、联合索引

c2和c3联合组成索引，也是非聚簇索引

**建立原则**：将查询要求频繁或者字段选择性高的列放在前面

<br>

> **InnoDB的B+树索引的注意事项**
>
> - 根页面位置万年不动
> 	- 开始又一个数据页，保存在内存中，一旦需要创建目录页时，会将原数据页向下复制到子节点，然后将数据页改成目录页，保证根的地址不动
> - 内节点中**目录项记录**的唯一性（不是索引唯一）
> 	- 如果表中数据c2全是1，以c2创建二级索引，查找目录页的时候不知道该往哪页找，会导致查询也很慢
> 	- 所以真实中二级索引的目录项中也会保存了主键值
> - 一个页面最少存储2条记录

<br>

**MyISAM中B+树索引的叶子结点存储的是数据记录的地址**

可以理解为MyISAM中都是非聚簇索引，没有聚簇索引，需要回表

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202203271420200.png" alt="image-20220327141929946" />

<br>

## 二、索引的数据结构

### 1、Hash索引

- 等值查询很快，但是范围查询的时候hash就不行了
- 存储无序，order by的时候还需要重新排序

- 联合索引时，hash是将联合的字段一起进行哈希计算，可能出现别的字段联合的哈希值相同
- 索引的重复值较多时，需要遍历，效率低

Memory支持（默认），InnoDB和MyISAM不支持

<br>

但是InnoDB支持**自适应的哈希索引**：一个数据多次被访问时，会将地址存放到Hash表中

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202203271434665.png" alt="image-20220327143408742" style="zoom:33%;" />

<br>

### 2、B+树索引

二叉搜索树 

AVL树（平衡二叉树）

B-Tree（B：Balance，多路平衡查找树） 

B+Tree



**B-Tree**

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202203271448896.png" alt="image-20220327144822430"  />

`所有节点都存放数据`

<br>

**B+Tree**

形式见前面InnoDB索引的图

- 从根节点到每个叶子结点的高度差不超过1，而且同层级的节点间有指针相互链接
- 搜索速度稳定
- 基于索引的顺序扫描时，可以利用双指针快速左右移动，效率高

> B-Tree和B+Tree各有各的使用场景，并不是B+Tree就是比B-Tree好

<br>

## 思考题

### 1、为了减少IO，索引树会一次性加载吗

- 数据库索引时存储在磁盘上的，如果数据量很大，索引的大小也会很大
- 所以逐一加载每一个磁盘页，因为磁盘页对应着索引树的节点

### 2、为什么说一般查找行记录，最多只需要1～3次磁盘IO

举例：InnoDB存储引擎中页的大小为16KB,一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree 中的一个节点）中大概存储16KB/(8B+3B)=1K个键值（因为是估值，为方便计算，这里的K取值为 10^3。也就是说一个深度为3的B+Tree 索引可以维护 10^3 * 10^3* 10^3=10 亿条记录。(这里假定一个数据页也存储10^3条行记录数据了)

实际中，每个节点不可能填充满，因此数据库中，**B+Tree的高度一般在2～4层**，InnoDB的根节点常驻内存，所以只需要1～3次磁盘IO操作。

### 3、Hash索引和B+Tree索引的区别

- Hash`不能进行范围查找`，是等值查询，因为其指向的数据是无序的（经过哈希计算后会无序），而B+的叶子结点是有序的
- Hash`不支持联合索引的最左侧原则`，即不能使用联合索引的部分索引，hash计算哈希值时将索引键合并计算，然后查找；B+Tree可以先找c2再找c3
- Hash`不支持order by排序`，也`不能模糊查询`
- `InnoDB不支持哈希索引`

<br>

## 三、索引的分类

- **功能逻辑**：普通索引、唯一性索引、主键索引、全文索引、空间索引（
- **物理实现方式**：聚簇索引、非聚簇索引
- **作用字段个数**：单列索引、联合索引

<br>

1. 普通索引
	- 可以创建在任何数据类型上
2. 唯一性索引
	- 添加unique约束的字段会自动添加唯一性索引，限制该索引的值必须唯一，但可以为null
3. 主键索引
	- 主键约束，最多只有一个（索引的物理实现方式决定，数据存储在文件中只能按照一种顺序进行存储）
	- 推荐自增主键，减少页分裂
4. 单列索引
	- 建立在一个字段
5. 多列（组合、联合）索引
	- 建立在多个字段上
	- 需要遵循`最左前缀集合`（最左侧原则）
6. 全文索引
	- FULLTEXT设置，只能在char、varchar、text上
	- 搜索引擎常用，分词技术
	- 被solr、ElasticSearch等专门等搜索引擎替代
7. 空间索引
	- spatial修饰，部分引擎具有
	- 作用在空间数据类型上geometry、point、linestring、polygon

<br>

## 四、索引的创建

见pdf



<br>

## 五、索引的设计原则

单表不要超过6个

> - 查询快，占用空间小
> - where，匹配度高
> - 基数大，区分度高
> - 尽量扩展索引，不新建，用联合索引
> - 更新频繁不适合
> - 短索引

<br>

### 1、适合创建

1. 字段值具有唯一性的限制

> 业务上具有唯一性的字段，即使是组合字段，也必须建成唯一索引。（Alibaba）
>
> 虽然唯一性索引影响了insert的速度，这个损耗可以忽略，但是查找速度的提高是明显的。

2. **频繁作为where查询条件的字段**

	- 普通索引就可以大幅提升数据查询的效率

3. 经常group by 和order by的列

	- 索引就是让数据按照某种顺序进行存储或检索，因此当我们使用 GROUP BY 对数据进行分组查询，或者使用 ORDER BY 对数据进行排序的时候，就需要`对分组或者排序的字段进行索引`。如果待排序的列有多 个，那么可以在这些列上建立`组合索引`。

4. update、delete的where条件列

	- 如果进行更新的时候，更新的字段是非索引字段，提升的效率会更明显，这是因为非索引字段更 新不需要对索引进行维护。

5. distinct（去重）字段需要创建索引

6. 多表join连接操作时，创建索引注意事项

	- 连接表的数量尽量不超过3张，每增加一张表就相当于增加了一次嵌套的循环
	- 对where条件创建索引
	- 对用于连接的字段创建索引，并且该字段在多张表中的类型必须一致

7. 使用列的类型小的创建索引

	- 越小，占用空间越小

8. **使用字符串前缀创建索引**

	- 使用字段前几个字符作为索引

	- 区分度`count(distinct left(列名, 索引长度)) / count(*)`
	- 越接近1，重复度越小；一般33%就算比较高效了
	- 倒序存储，再前缀索引，避免前缀区分度不高的情况

9. 区分度高（散列性高）的列适合作为索引

10. 使用频繁的列放到联合索引的左侧

	- (a,b,c)，先a排序，再b再c

11. 再多个字段都要创建索引的情况下，联合索引优于单值索引



<br>

### 2、不适合创建

1. 数据量小的表最好不要使用索引（不超过100行）
2. where，group by 和 order by 中使用不到的字段，不要设置索引
3. 有大量重复数据的列上不要建立索引（高于10%），即区分度低
4. 避免对经常更新的表创建过多的索引
5. 不用无序的值作为索引
6. 删除不再使用或者很少使用的索引
7. 不要定义冗余或重复的索引
	- 冗余：定义联合索引（a,b,c），又定义索引a





## 六、索引失效的情况

1. 以“%”开头的like语句，索引无效，后缀“%”不影响
2. `or`语句前后没有`同时使用索引`
3. 列类型是字符串，一定要在条件中将数据用`引号引用`，否则失效（隐式转换）
4. 如果mysql估计使用全表扫描比索引快，则不用索引（键值少，重复数据多）
5. 组合索引要遵守`最左前缀原则`——不使用第一列索引 失效
6. 在索引字段上使用not，<>，!= （对它处理是全表扫描）
7. 计算、函数、类型转换（自动或手动）导致索引失效
8. is null可以使用索引，is not null无法使用索引
9. 范围条件右边的列索引失效
10. 数据库和表的字符集统一使用utf8mb4



# 锁

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205112056261.png" alt="image-20220511205635387" style="zoom: 50%;" />

## 从类型划分：读锁S、写锁X

### 锁定读

- 对读取的记录加S锁

```sql
select ... lock in share mode;
# or
select ... for share; #8.0新增语法
```

- 对读取的记录加X锁

```sql
select ... for update;
```

查询语句不会产生锁，但是select ..... for update例外

- 如果查询条件用了索引/主键，那么select ..... for update就会进行`行锁`。

- 如果是普通字段(没有索引/主键)，那么select ..... for update就会进行`表锁`。

### 写操作

- `DELETE`：对一条记录做DELETE操作的过程其实是先在`B+`树中定位到这条记录的位置，然后获取这条记录的`X锁`，再执行`delete mark`操作。

- `UPDATE`：在对一条记录做UPDATE操作时分为三种情况：

	- 情况1：未修改该记录的键值，并且被更新的列占用的存储空间在修改前后未发生变化。

		则先在`B+`树中定位到这条记录的位置，然后再获取一下记录的`X锁`，最后在原记录的位置进行修改操作。

	- 情况2：未修改该记录的键值，并且至少有一个被更新的列占用的存储空间在修改前后发生变化。

		则先在`B+`树中定位到这条记录的位置，然后获取一下记录的`X锁`，将该记录彻底删除掉（就是把记录彻底移入垃圾链表），最后再插入一条新记录。新插入的记录由`INSERT`操作提供的`隐式锁`进行保护。

	- 情况3：修改该记录的键值，则相当于在原记录上做`DELECT`操作之后再来一次`INSERT`操作。

- `INSERT`：一般情况下，新插入一条记录的操作并不加锁，通过一种称之为`隐式锁`的结构来保护这条新插入的记录在本事务提交前不被别的事务访问。

## 锁粒度划分：表锁、行锁、页锁

### 表锁

#### 1、表级别的S锁、X锁

一般情况下，不会使用InnoDB存储引擎提供的表级别的`S锁`和`X锁`。只会在一些特殊情况下，比方说`崩溃恢复`过程中用到。比如，在系统变量`autocommit=0，innodb_table_locks = 1`时，`手动`获取InnoDB存储引擎提供的表t 的`S锁`或者`X锁`可以这么写：

- `LOCK TABLES t READ`：InnoDB存储引擎会对表`t`加表级别的`S锁`。 

- `LOCK TABLES t WRITE`：InnoDB存储引擎会对表`t`加表级别的`X锁`。

总结：MyISAM在执行查询语句（SELECT）前，会给涉及的所有表加读锁，在执行增删改操作前，会给涉及的表加写锁。`InnoDB`存储引擎是不会为这个表添加表级别的`读锁`或者`写锁`的。

#### 2、意向锁

InnoDB 支持`多粒度锁（multiple granularity locking）`，它允许`行级锁`与`表级锁`共存，而**意向锁**就是其中的一种`表锁`。

**意向锁要解决的问题**

在数据表的场景中，**如果我们给某一行数据加上了排它锁，数据库会自动给更大一级的空间，比如数据页或数据表加上意向锁，告诉其他人这个数据页或数据表已经有人上过排它锁了**，这样当其他人想要获取数据表排它锁的时候，只需要了解是否有人已经获取了这个数据表的意向排它锁即可，其他人进行操作就会自动阻塞，不需要再去找是否存在排他锁了。

- 如果事务想要获取数据表中某些记录的共享锁，就需要在数据表上`添加意向共享锁`
- 如果事务想要获取数据表中某些记录的排它锁，就需要在数据表上`添加意向排他锁`

这时，意向锁会告诉其他事务已经有人锁定了表中的某些记录。

**意向锁分为两种**：

- **意向共享锁**（intention shared lock, IS）：事务有意向对表中的某些行加**共享锁**（S锁）

```mysql
-- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。 
SELECT column FROM table ... LOCK IN SHARE MODE;
```

- **意向排他锁**（intention exclusive lock, IX）：事务有意向对表中的某些行加**排他锁**（X锁）

```mysql
-- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。 
SELECT column FROM table ... FOR UPDATE;
```

即：意向锁是由存储引擎`自己维护的`，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行`所在数据表的对应意向锁`。

#### 3、自增锁

`AUTO_INCREMENT`

#### 4、元数据锁

MDL 的作用是，保证读写的正确性。比如，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个`表结构做变更`，增加了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

因此，**当对一个表做增删改查操作的时候，自动加MDL读锁；当要对表做结构变更操作的时候，自动加MDL写锁。**

### 行锁

行锁（Row Lock）也称为记录锁，顾名思义，就是锁住某一行（某条记录row）。需要注意的是，MySQL服务器层并没有实现行锁机制，**行级锁只在存储引擎层实现。**

**优点：**锁定力度小，发生`锁冲突概率低`，可以实现的`并发度高`

**缺点：**对于`锁的开销比较大`，加锁会比较慢，容易出现`死锁`情况

InnoDB与MyISAM的最大不同有两点：一是支持事务；二是采用了行级锁。

#### 1、记录锁

记录锁也就是仅仅把一条记录锁上，官方的类型名称为：`LOCK_REC_NOT_GAP`。

记录锁是有S锁和X锁之分的，称之为`S型记录锁`和`X型记录锁`。

- 当一个事务获取了一条记录的S型记录锁后，其他事务也可以继续获取该记录的S型记录锁，但不可以继续获取X型记录锁；
- 当一个事务获取了一条记录的X型记录锁后，其他事务既不可以继续获取该记录的S型记录锁，也不可以继续获取X型记录锁。

#### 2、间隙锁

`MySQL`在`REPEATABLE READ`隔离级别下是可以解决幻读问题的，解决方案有两种，可以使用`MVCC`方案解决，也可以采用`加锁`方案解决。

但是在使用加锁方案解决时有个大问题，就是事务在第一次执行读取操作时，那些幻影记录尚不存在，我们无法给这些`幻影记录`加上`记录锁`。InnoDB提出了一种称之为`Gap Locks`的锁，官方的类型名称为：`LOCK_GAP`，我们可以简称为`gap锁`。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205112105930.png" alt="image-20220511210540436" style="zoom:50%;" />

图中id值为8的记录加了gap锁，意味着 不允许别的事务在id值为8的记录前边的间隙插入新记录 ，其实就是 id列的值(3, 8)这个区间的新记录是不允许立即插入的。

比如，有另外一个事务再想插入一条id值为4的新记录，它定位到该条新记录的下一条记录的id值为8，而这条记录上又有一个gap锁，所以就会阻塞插入操作，直到拥有这个gap锁的事务提交了之后，id列的值在区间(3, 8)中的新记录才可以被插入。

**gap锁的提出仅仅是为了防止插入幻影记录而提出的**。虽然有`共享gap锁`和`独占gap锁`这样的说法，但是它们起到的作用是相同的。而且如果对一条记录加了gap锁（不论是共享gap锁还是独占gap锁），并不会限制其他事务对这条记录加记录锁或者继续加gap锁。

#### 3、临键锁

有时候我们既想`锁住某条记录`，又想`阻止`其他事务在该记录前边的`间隙插入新记录`，所以InnoDB就提出了一种称之为`Next-Key Locks`的锁，官方的类型名称为：`LOCK_ORDINARY`，我们也可以简称为`next-key锁`。Next-Key Locks是在存储引擎`innodb`、事务级别在`可重复读`的情况下使用的数据库锁，innodb默认的锁就是Next-Key locks。 

```mysql
begin; 
select * from student where id <=8 and id > 3 for update;
```

#### 4、插入意向锁

一个事务在`插入`一条记录时需要判断一下插入位置是不是被别的事务加了`gap锁`（`next-key锁`也包含`gap锁`），如果有的话，插入操作需要等待，直到拥有`gap锁`的那个事务提交。但是**InnoDB规定事务在等待的时候也需要在内存中生成一个锁结构**，表明有事务想在某个`间隙`中`插入`新记录，但是现在在等待。

InnoDB就把这种类型的锁命名为`Insert Intention Locks`，官方的类型名称为：`LOCK_INSERT_INTENTION`，我们称为`插入意向锁`。

插入意向锁是一种`Gap锁`，不是意向锁，在insert操作时产生。

插入意向锁是在插入一条记录行前，由`INSERT 操作产生的一种间隙锁`。

事实上**插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁。**

## 锁结构

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205112125785.png" alt="image-20220405151409557" style="zoom:80%;" />

# MVCC多版本并发控制

MVCC (Multiversion Concurrency Control) 是通过数据行的多个版本管理来实现数据库的并发控制 

读取数据时通过⼀种类似快照的⽅式将数据保存下来，这样读锁就和写锁不冲突了，不同的事务 session 会看到⾃⼰特定版本的数据、版本链。 

**MVCC 的实现依赖于：隐藏字段、Undo Log、Read View。**

- 隐藏字段

	- `trx_id`：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的`事务id`赋值给trx_id 隐藏列。

	- `roll_pointer`：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到 undo日志 中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。

MVCC 只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下⼯作。其他两个隔离级别和MVCC不兼容, 因为 READ UNCOMMITTED 总是读取最新的数据⾏, ⽽不是符合当前事务版本的数据⾏。⽽ SERIALIZABLE 则会对所有读取的⾏都加锁。 

<br>

## ReadView

ReadView 就是事务在使用 MVCC 机制进行快照读操作时产生的读视图

**快照**

- 快照读又叫一致性读，读取的是快照数据。
- **不加锁的简单的** **SELECT** **都属于快照读**，即不加锁的非阻塞读。

记录已提交事务所做的更改

ReadView的存在本身就保证了 事务不可以读取到未提交的事务所做的更改 ，也就是避免了脏读现象

### 四个重要属性

1. `creator_trx_id`，创建这个 Read View 的事务 ID。

> 说明：只有在对表中的记录做改动时（执行INSERT、DELETE、UPDATE这些语句时）才会为事务分配事务id，否则在一个只读事务中的事务id值都默认为0。 

2. `trx_ids`，表示在生成ReadView时当前系统中活跃的读写事务的`事务id列表`。 

3. `up_limit_id`，活跃的事务中最小的事务 ID。 

4. `low_limit_id`，表示生成ReadView时系统中应该分配给下一个事务的`id`值。low_limit_id 是系统最大的事务id值，这里要注意**是系统中的事务id**，需要区别于正在活跃的事务ID。

> 注意：low_limit_id并不是trx_ids中的最大值，事务id是递增分配的。比如，现在有id为1， 2，3这三个事务，之后id为3的事务提交了。那么一个新的读事务在生成ReadView时，trx_ids就包括1和2，up_limit_id的值就是1，low_limit_id的值就是4。

### 规则

有了这个ReadView，这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见。

- 如果被访问版本的trx_id属性值与ReadView中的`creator_trx_id`值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。
- 如果被访问版本的trx_id属性值小于ReadView中的`up_limit_id`值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。
- 如果被访问版本的trx_id属性值大于或等于ReadView中的`low_limit_id`值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。
- 如果被访问版本的trx_id属性值在ReadView的`up_limit_id`和`low_limit_id`之间，那就需要判断一下trx_id属性值是不是在 trx_ids 列表中。
	- 如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问。
	- 如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。

### 流程

1. 首先获取事务自己的版本号，也就是事务 ID； 
2. 获取 ReadView； 
3. 查询得到的数据，然后与 ReadView 中的事务版本号进行比较；
4. 如果不符合 ReadView 规则，就需要从 Undo Log 中获取历史快照；
5. 最后返回符合规则的数据。



**已提交读和可重复读的区别就在于它们⽣成ReadView的策略不同。** 

- **已提交读隔离级别**下的事务在每次查询的开始都会⽣成⼀个独⽴的ReadView，

- **可重复读隔离级别**则在第⼀次读的时候⽣成⼀个ReadView，之后的读都`复⽤`之前的ReadView。 `这样避免了不可重复读和幻读的问题`

这就是Mysql的MVCC,通过版本链，实现多版本，可并发读-写，写-读。通过ReadView⽣成策略的不同实现不同的隔离级别。 



# 分析查询语句：EXPLAIN

```sql
EXPLAIN SELECT select_options 
#或者
DESCRIBE SELECT select_options
```



| 列名          | 描述                                                     |
| ------------- | -------------------------------------------------------- |
| id            | 在一个大的查询语句中每个SELECT关键字都对应一个`唯一的id` |
| select_type   | SELECT关键字对应的那个查询的类型                         |
| table         | 表名                                                     |
| partitions    | 匹配的分区信息                                           |
| type          | 针对单表的访问方法                                       |
| possible_keys | 可能用到的索引                                           |
| key           | 实际上使用的索引                                         |
| key_len       | 实际使用到的索引长度                                     |
| ref           | 当使用索引列等值查询时，与索引列进行等值匹配的对象信息   |
| rows          | 预估的需要读取的记录条数                                 |
| filtered      | 某个表经过搜索条件过滤后剩余记录条数的百分比             |
| Extra         | 一些额外的信息                                           |



# 数据库调优

哪些维度可以进行数据库调优？

- 索引失效，没有充分利用到索引——索引建立
- 关联查询太多JOIN（设计缺陷或不得已的需求）——SQL优化
- 服务器调优及各个参数设置（缓冲、线程数等）——调整my.cnf
- 数据过多——分库分表
